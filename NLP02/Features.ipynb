{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in c:\\users\\$0nt000-3g88gugfr0b8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in c:\\users\\$0nt000-3g88gugfr0b8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from vaderSentiment) (2.28.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\$0nt000-3g88gugfr0b8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->vaderSentiment) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\$0nt000-3g88gugfr0b8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->vaderSentiment) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\$0nt000-3g88gugfr0b8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->vaderSentiment) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\$0nt000-3g88gugfr0b8\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->vaderSentiment) (3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment\n",
    "import datasets\n",
    "import requests\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (C:/Users/$0NT000-3G88GUGFR0B8/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "100%|██████████| 3/3 [00:00<00:00, 198.46it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_dataset('imdb')\n",
    "\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/cjhutto/vaderSentiment/master/vaderSentiment/vader_lexicon.txt\"\n",
    "response = requests.get(url)\n",
    "text = response.text\n",
    "lexicon_words = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase_punctuation(text):\n",
    "    newtext = text.lower()\n",
    "    # remove <br /> tags\n",
    "    newtext = newtext.replace('<br />', '')\n",
    "    # remove punctuation\n",
    "    newtext = ''.join([c if c not in \"\\\"#$%&()*+,./:;<=>?@[\\]^_`{|}~\" else ' ' for c in newtext])\n",
    "    return newtext.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pronouns(word_list):\n",
    "    count = 0\n",
    "    for word in word_list:\n",
    "        if word in [\"i\", \"you\", \"we\"]:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexicon_word_counter(word_list):\n",
    "    positive_count = 0\n",
    "    negative_count = 0\n",
    "    lower_lexicon_value = -1\n",
    "    upper_lexicon_value = 1\n",
    "    for word in word_list:\n",
    "        if word in lexicon_words:\n",
    "            sentimental_value = 0\n",
    "            if isinstance(lexicon_words[lexicon_words.index(word) + 1], str):\n",
    "                continue\n",
    "            if float(sentimental_value) < lower_lexicon_value:\n",
    "                negative_count += 1\n",
    "            elif float(sentimental_value) > upper_lexicon_value:\n",
    "                positive_count += 1\n",
    "    return positive_count, negative_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_generator(dataset):\n",
    "    resulting_vector = []\n",
    "    for obj in dataset:\n",
    "        current_vector = []\n",
    "        word_list = lowercase_punctuation(obj['text'])\n",
    "        current_vector.append(1) if word_list.__contains__('no') else current_vector.append(0)\n",
    "        current_vector.append(count_pronouns(word_list))\n",
    "        current_vector.append(1) if word_list.__contains__('!') else current_vector.append(0)\n",
    "        current_vector.append(np.log(len(word_list)))\n",
    "        positive_count, negative_count = lexicon_word_counter(word_list)\n",
    "        current_vector.append(positive_count)\n",
    "        current_vector.append(negative_count)\n",
    "        resulting_vector.append(current_vector)\n",
    "    return resulting_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vector_generator(train_dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
