{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset_builder\n",
    "import datasets\n",
    "\n",
    "ds_builder = load_dataset_builder(\"imdb\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dataset\n",
    "\n",
    "How many split does the dataset has ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data set has 3 splits !\n"
     ]
    }
   ],
   "source": [
    "nb_splits = len(ds_builder.info.splits)\n",
    "print(\"The data set has {} splits !\".format(nb_splits))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big are these splits ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': SplitInfo(name='train', num_bytes=33432823, num_examples=25000, shard_lengths=None, dataset_name='imdb'),\n",
       " 'test': SplitInfo(name='test', num_bytes=32650685, num_examples=25000, shard_lengths=None, dataset_name='imdb'),\n",
       " 'unsupervised': SplitInfo(name='unsupervised', num_bytes=67106794, num_examples=50000, shard_lengths=None, dataset_name='imdb')}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_builder.info.splits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of train split is 25000\n",
    "The size of test split is 25000\n",
    "The size of unsupervised split is 50000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the proportion of each class on the supervised splits ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (C:/Users/$0NT000-3G88GUGFR0B8/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "100%|██████████| 3/3 [00:00<00:00, 53.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 25000 Train pos: 12500 Train neg: 12500\n",
      "Test size: 25000 Test pos: 12500 Test neg: 12500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_dataset('imdb')\n",
    "\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']\n",
    "\n",
    "train_size = len(train_dataset)\n",
    "test_size = len(test_dataset)\n",
    "\n",
    "train_pos = sum(train_dataset['label'])\n",
    "train_neg = train_size - train_pos\n",
    "test_pos = sum(test_dataset['label'])\n",
    "test_neg = test_size - test_pos\n",
    "\n",
    "# Print the results\n",
    "\n",
    "print('Train size: {} Train pos: {} Train neg: {}'.format(train_size, train_pos, train_neg))\n",
    "print('Test size: {} Test pos: {} Test neg: {}'.format(test_size, test_pos, test_neg))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the dataset contains the column \"text\" (that contains string) and the colums \"label\" (that contains class \"neg\" or \"pos\") that indicate if it's a positive or a negative comment\n",
    "\n",
    "Train split contains 12500 pos (50%) and 12500 neg (50%)\n",
    "Test split contains 12500 pos (50%) and 12500 neg (50%)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lower case the text and replace punctuation with space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase_punctuation(text):\n",
    "    newtext = text.lower()\n",
    "    # remove <br /> tags\n",
    "    newtext = newtext.replace('<br />', '')\n",
    "    # remove punctuation\n",
    "    newtext = ''.join([c if c not in \"!\\\"#$%&()*+,./:;<=>?@[\\]^_`{|}~\" else ' ' for c in newtext])\n",
    "    return newtext\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement your own naive Bayes classifier from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def get_all_words(dataset):\n",
    "    all_words = []\n",
    "    for obj in dataset:\n",
    "        all_words += lowercase_punctuation(obj[\"text\"]).split()\n",
    "    #remove double\n",
    "    all_words = list(set(all_words))\n",
    "    return all_words\n",
    "\n",
    "def bigdoc(dataset, feature):\n",
    "    bigdoc = []\n",
    "    for obj in dataset:\n",
    "        if (obj[\"label\"] == feature):\n",
    "            bigdoc += lowercase_punctuation(obj[\"text\"]).split() # pre process and add all words of the document to the bigdoc\n",
    "    return bigdoc\n",
    "\n",
    "def train_naive_bayes_classifier_scratch(dataset, features):\n",
    "    words = get_all_words(dataset)\n",
    "    nbwords = len(words)\n",
    "    logprior = np.zeros(len(features))\n",
    "    loglikelihood = np.zeros((len(features), len(words)))\n",
    "    ndoc = len(dataset)\n",
    "    for feature in features:\n",
    "        nc = dataset[\"label\"].count(feature) # number of documents with class c\n",
    "        logprior[feature] = np.log(nc/ndoc)\n",
    "        bigd = bigdoc(dataset, feature)\n",
    "        lgbigd = len(bigd)\n",
    "        count = Counter(bigd)\n",
    "        for i, word in enumerate(words):\n",
    "            c = count[word]\n",
    "            loglikelihood[feature, i] = np.log((c + 1)/(lgbigd + nbwords))\n",
    "    return logprior, loglikelihood, words\n",
    "\n",
    "\n",
    "train_dataset = dataset['train']\n",
    "logprior, loglikelihood, words = train_naive_bayes_classifier_scratch(train_dataset, [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81504\n"
     ]
    }
   ],
   "source": [
    "def predict_string(test_string, logprior, loglikelihood, C, vocab_dict):\n",
    "    sum = np.zeros(len(C))\n",
    "    for c in C:\n",
    "        sum[c] = logprior[c]\n",
    "        target_word_list = lowercase_punctuation(test_string).split()\n",
    "        for word in target_word_list:\n",
    "            if word in vocab_dict:\n",
    "                sum[c] = sum[c] + loglikelihood[c, vocab_dict[word]]\n",
    "    return np.argmax(sum)\n",
    "\n",
    "def test_naive_bayes_classifier_scratch(test_dataset, logprior, loglikelihood, C, V):\n",
    "    word_dict = {word: i for i, word in enumerate(V)}\n",
    "    total = len(test_dataset)\n",
    "    correct = 0\n",
    "    for obj in test_dataset:\n",
    "        pred = predict_string(obj[\"text\"], logprior, loglikelihood, C, word_dict)\n",
    "        if pred == obj[\"label\"]:\n",
    "            correct += 1\n",
    "    print(\"Accuracy: {}\".format(correct/total))\n",
    "\n",
    "test_dataset = dataset['test']\n",
    "test_naive_bayes_classifier_scratch(test_dataset, logprior, loglikelihood, [0, 1], words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Implement a naive Bayes classifier using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "train_dataset = dataset['train']\n",
    "\n",
    "def train_naive_bayes_classifier_scikit(train_dataset):\n",
    "    vectorizer = CountVectorizer(lowercase=True, stop_words=\"english\")\n",
    "    X_train = vectorizer.fit_transform(train_dataset[\"text\"])\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train, train_dataset[\"label\"])\n",
    "    pipeline = make_pipeline(vectorizer, model)\n",
    "    return pipeline\n",
    "\n",
    "pipeline = train_naive_bayes_classifier_scikit(train_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81968\n"
     ]
    }
   ],
   "source": [
    "def test_naive_bayes_classifier_scikit(test_dataset, pipeline):\n",
    "    correct = 0\n",
    "    total = len(test_dataset)\n",
    "    for obj in test_dataset:\n",
    "        pred = pipeline.predict([obj[\"text\"]])\n",
    "        if pred == obj[\"label\"]:\n",
    "            correct += 1\n",
    "    print(\"Accuracy: {}\".format(correct/total))\n",
    "\n",
    "test_dataset = dataset['test']\n",
    "test_naive_bayes_classifier_scikit(test_dataset, pipeline)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes Classifier from scratch : accuracy = 0.815 (81.5% correct)\n",
    "Naive Bayes Classifier SciKit : accuracy = 0.819 (81.9% correct)\n",
    "\n",
    "The difference can be caused by the pre processing of the text. Scikit for example remove words that are useless like \"the\" or \"and\" for example. This can lead to better accuracy. Scikit also have differents features like the CoutnVectorizer that allows to get more context in each text. So Scikit is a bit more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Isaac Florentine has made some of the best western Martial Arts action movies ever produced. In particular US Seals 2, Cold Harvest, Special Forces and Undisputed 2 are all action classics. You can tell Isaac has a real passion for the genre and his films are always eventful, creative and sharp affairs, with some of the best fight sequences an action fan could hope for. In particular he has found a muse with Scott Adkins, as talented an actor and action performer as you could hope for. This is borne out with Special Forces and Undisputed 2, but unfortunately The Shepherd just doesn't live up to their abilities.<br /><br />There is no doubt that JCVD looks better here fight-wise than he has done in years, especially in the fight he has (for pretty much no reason) in a prison cell, and in the final showdown with Scott, but look in his eyes. JCVD seems to be dead inside. There's nothing in his eyes at all. It's like he just doesn't care about anything throughout the whole film. And this is the leading man.<br /><br />There are other dodgy aspects to the film, script-wise and visually, but the main problem is that you are utterly unable to empathise with the hero of the film. A genuine shame as I know we all wanted this film to be as special as it genuinely could have been. There are some good bits, mostly the action scenes themselves. This film had a terrific director and action choreographer, and an awesome opponent for JCVD to face down. This could have been the one to bring the veteran action star back up to scratch in the balls-out action movie stakes.<br /><br />Sincerely a shame that this didn't happen.\n",
      "Predicted: 1\n",
      "Actual: 0\n",
      "\n",
      "Text: Blind Date (Columbia Pictures, 1934), was a decent film, but I have a few issues with this film. First of all, I don't fault the actors in this film at all, but more or less, I have a problem with the script. Also, I understand that this film was made in the 1930's and people were looking to escape reality, but the script made Ann Sothern's character look weak. She kept going back and forth between suitors and I felt as though she should have stayed with Paul Kelly's character in the end. He truly did care about her and her family and would have done anything for her and he did by giving her up in the end to fickle Neil Hamilton who in my opinion was only out for a good time. Paul Kelly's character, although a workaholic was a man of integrity and truly loved Kitty (Ann Sothern) as opposed to Neil Hamilton, while he did like her a lot, I didn't see the depth of love that he had for her character. The production values were great, but the script could have used a little work.\n",
      "Predicted: 1\n",
      "Actual: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def find_wrong_prediction_scratch(test_dataset, logprior, loglikelihood, C, V):\n",
    "    i = 0\n",
    "    word_dict = {word: i for i, word in enumerate(V)}\n",
    "    for obj in test_dataset:\n",
    "        pred = predict_string(obj[\"text\"], logprior, loglikelihood, C, word_dict)\n",
    "        if pred != obj[\"label\"]:\n",
    "            print(\"Text: {}\".format(obj[\"text\"]))\n",
    "            print(\"Predicted: {}\".format(pred))\n",
    "            print(\"Actual: {}\".format(obj[\"label\"]))\n",
    "            print(\"\")\n",
    "            i += 1\n",
    "            if (i == 2):\n",
    "                break\n",
    "\n",
    "test_dataset = dataset['test']\n",
    "find_wrong_prediction_scratch(test_dataset, logprior, loglikelihood, [0, 1], words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of those comments are quite lengthy and contain both positive and negative words. The Naive Bayes classifier cannot accurately interpret the context of the expressions, so it is normal that it fails."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\$0NT000-\n",
      "[nltk_data]     3G88GUGFR0B8\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import datasets\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def stemming(dataset: datasets.arrow_dataset) -> datasets.arrow_dataset:\n",
    "    re_word = re.compile(r\"^\\w+$\")\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "    stemmed = [stemmer.stem(word) for word in word_tokenize(dataset['text'].lower()) if re_word.match(word)]\n",
    "    dataset['text'] = \" \".join(stemmed)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\$0NT000-3G88GUGFR0B8\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0\\cache-ec50cdf0016b7d38.arrow\n",
      "                                                                  \r"
     ]
    }
   ],
   "source": [
    "stemmed_train = train_dataset.map(stemming)\n",
    "stemmed_test = test_dataset.map(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81244\n"
     ]
    }
   ],
   "source": [
    "trained_stem = train_naive_bayes_classifier_scikit(stemmed_train)\n",
    "test_naive_bayes_classifier_scikit(stemmed_test, trained_stem)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit without stemming : accuracy = 0.819 (81.9%)\n",
    "Scikit with stemming : accuracy =  0.812 (81.2%)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stemming is a process that reduce words to their root form by cutting prefixes and suffixes.\n",
    "In some case stemming can lead to a significant loss of information or context (\"found\" or \"finder\" will become \"find\" for example). So this can decrease the model's accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
